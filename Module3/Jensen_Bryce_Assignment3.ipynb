{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (50000, 32, 32, 3)\n",
      "50000  train samples\n",
      "10000  test samples\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Augmenting training set images...\n",
      "X_train shape:  (50000, 32, 32, 3)\n",
      "50000  train samples\n",
      "10000  test samples\n",
      "Before Fitting the datagen\n",
      "X_train shape:  (50000, 32, 32, 3)\n",
      "50000  train samples\n",
      "10000  test samples\n",
      "Before Train\n",
      "X_train shape:  (50000, 32, 32, 3)\n",
      "50000  train samples\n",
      "10000  test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:164: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=20, verbose=1, steps_per_epoch=390)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "390/390 [==============================] - 117s 300ms/step - loss: 1.8664 - accuracy: 0.3137\n",
      "Epoch 2/20\n",
      "390/390 [==============================] - 120s 307ms/step - loss: 1.6055 - accuracy: 0.4179\n",
      "Epoch 3/20\n",
      "390/390 [==============================] - 118s 303ms/step - loss: 1.4846 - accuracy: 0.4620\n",
      "Epoch 4/20\n",
      "390/390 [==============================] - 117s 299ms/step - loss: 1.4107 - accuracy: 0.4899\n",
      "Epoch 5/20\n",
      "390/390 [==============================] - 122s 313ms/step - loss: 1.3474 - accuracy: 0.5154\n",
      "Epoch 6/20\n",
      "390/390 [==============================] - 117s 301ms/step - loss: 1.3097 - accuracy: 0.5320\n",
      "Epoch 7/20\n",
      "390/390 [==============================] - 120s 307ms/step - loss: 1.2700 - accuracy: 0.5428\n",
      "Epoch 8/20\n",
      "390/390 [==============================] - 119s 305ms/step - loss: 1.2487 - accuracy: 0.5536\n",
      "Epoch 9/20\n",
      "390/390 [==============================] - 118s 303ms/step - loss: 1.2143 - accuracy: 0.5644\n",
      "Epoch 10/20\n",
      "390/390 [==============================] - 130s 334ms/step - loss: 1.1954 - accuracy: 0.5758\n",
      "Epoch 11/20\n",
      "390/390 [==============================] - 120s 307ms/step - loss: 1.1799 - accuracy: 0.5810\n",
      "Epoch 12/20\n",
      "390/390 [==============================] - 121s 311ms/step - loss: 1.1577 - accuracy: 0.5864\n",
      "Epoch 13/20\n",
      "390/390 [==============================] - 117s 301ms/step - loss: 1.1363 - accuracy: 0.5991\n",
      "Epoch 14/20\n",
      "390/390 [==============================] - 117s 299ms/step - loss: 1.1309 - accuracy: 0.5984\n",
      "Epoch 15/20\n",
      "390/390 [==============================] - 120s 308ms/step - loss: 1.1155 - accuracy: 0.6036\n",
      "Epoch 16/20\n",
      "390/390 [==============================] - 117s 300ms/step - loss: 1.1024 - accuracy: 0.6080\n",
      "Epoch 17/20\n",
      "390/390 [==============================] - 121s 310ms/step - loss: 1.0956 - accuracy: 0.6147\n",
      "Epoch 18/20\n",
      "390/390 [==============================] - 120s 307ms/step - loss: 1.0753 - accuracy: 0.6175\n",
      "Epoch 19/20\n",
      "390/390 [==============================] - 120s 308ms/step - loss: 1.0683 - accuracy: 0.6243\n",
      "Epoch 20/20\n",
      "390/390 [==============================] - 122s 313ms/step - loss: 1.0485 - accuracy: 0.6298\n",
      "10000/10000 [==============================] - 10s 974us/step\n",
      "Test score:  1.1488510252952575\n",
      "Test accuracy:  0.6287000179290771\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl\n",
    "import os\n",
    "\n",
    "os.makedirs('preview', exist_ok=True) \n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "#CIFAR_10 set of 60k images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "#CONSTANTS\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "#load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# # Remove after testing\n",
    "# X_train = X_train[:10000]\n",
    "# y_train = y_train[:10000]\n",
    "# X_test = X_test[:2000]\n",
    "# y_test = y_test[:2000]\n",
    "# #######################\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(X_train.shape[0], \" train samples\")\n",
    "print(X_test.shape[0], \" test samples\")\n",
    "\n",
    "#convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "#float and normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', \n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "NUM_TO_AUGMENT = 5\n",
    "\n",
    "#load dataset\n",
    "#(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# augmenting\n",
    "print(\"Augmenting training set images...\")\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(X_train.shape[0], \" train samples\")\n",
    "print(X_test.shape[0], \" test samples\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "    x = X_train[i] # (3, 32, 32)\n",
    "    x = x.reshape((1,) + x.shape) # (1, 3, 32, 32)\n",
    "    for x_aug in datagen.flow(x, batch_size=1, \n",
    "                              save_to_dir='preview', \n",
    "                              save_prefix='cifar', \n",
    "                              save_format='jpeg'):\n",
    "        if num_aug >= NUM_TO_AUGMENT:\n",
    "            break\n",
    "        xtas.append(x_aug[0])\n",
    "        ytas.append(y_train[i]) # assuming that y_train is available\n",
    "        num_aug += 1\n",
    "\n",
    "print(\"Before Fitting the datagen\")\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(X_train.shape[0], \" train samples\")\n",
    "print(X_test.shape[0], \" test samples\")\n",
    "\n",
    "#fit the datagen\n",
    "datagen.fit(X_train)\n",
    "\n",
    "print(\"Before Train\")\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(X_train.shape[0], \" train samples\")\n",
    "print(X_test.shape[0], \" test samples\")\n",
    "\n",
    "#train\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(\n",
    "        X_train, \n",
    "        Y_train, \n",
    "        batch_size=BATCH_SIZE),\n",
    "    samples_per_epoch=X_train.shape[0],\n",
    "    epochs=NB_EPOCH,\n",
    "    verbose=VERBOSE)\n",
    "\n",
    "score = model.evaluate(\n",
    "    X_test,\n",
    "    Y_test, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=VERBOSE)\n",
    "print(\"Test score: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How this algorithm could result in ethical and privacy concerns if it were trained on different sets of images.\n",
    "\n",
    "Different sets of images could have several ethical or privacy concerns. Some that come to mind are:\n",
    "- If trained on images of humans, there may be some kind of bias toward a certain demographic or group of people. The model may learn to recognize patterns that are specific to that group, leading to unfair outcomes when applied to other groups.\n",
    "- It may learn to recognize features that are not relevant to the intended classification task, but are still present in the training data. For example, if the training dataset contains images of only GREEN frogs, then it may determine that a blue and orange frog is not a frog at all and may try to place it into some other classification.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
